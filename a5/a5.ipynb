{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP4220: Machine Learning, Spring 2022, Assignment 5\n",
    "\n",
    "> ## **Please submit one pdf file for all questions.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. List five hyperparameters you can tweak in a basic neural network?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. What is backpropagation and how does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment (Artificial Neural Network-ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_score, accuracy_score, f1_score, recall_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset. This dataset describes churning, which is\n",
    "# the rate at which customers stop doing business with a company\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Looking at the dataset we can see that the first 3 columns are not essential for our model. \n",
    "> Make a X variable that contains all other columns except the first three columns and Exited (label) <br/>\n",
    "> Make a Y variable (the Exited column) <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 3:13].values # Select input features X \n",
    "y = dataset.iloc[:, 13].values   # The last column \"Exited\" is the output variable Y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. In X there are Geography and Gender columns that are in string format which we can't use for training. Thus we should transform them into numerical type to train our model.\n",
    "> Use LabelEncoder and OneHotEncoder from sklearn.preprocessing to <br/>\n",
    "> transform the \"Geography\" and \"Gender\" columns into numberical data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "ct = ColumnTransformer([(\"Geogrophy\", OneHotEncoder(), [1])], remainder = 'passthrough')\n",
    "X = ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split the dataset into the Training set and Test set (test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Apply Feature Scaling to all features before training a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Let's build ANN model by using the Keras sequential package\n",
    "> Initalize the sequential model <br/>\n",
    "> Add the input layer and the first hidden layer <br/>\n",
    "> Hint: For the first layer use (units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Add the second hidden layer\n",
    "> Hint:(units = 6, kernel_initializer = 'uniform', activation = 'relu') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Add the output layer\n",
    "> Hint: (units = 1, kernel_initializer = 'uniform', activation = 'sigmoid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Compile the ANN\n",
    "> hint: (optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Fit the ANN to the training set\n",
    "> (batch_size = 5, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = \n",
    "epochs = \n",
    "history = classifier.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Make predictions and evaluate the model\n",
    "> hint: just consider y_pred the values where y_pred is greater than 0.5 <br/>\n",
    "> (y_pred = (y_pred > 0.5)) <br/>\n",
    "> Make the confusion matrix and show the result <br/>\n",
    "> Evalue the precision, accuracy, recall, and f1 score and show the result <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Compute the accuracy, precision, recall, and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: {}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('Precision: {}'.format(precision_score(y_test, y_pred)))\n",
    "print('Recall: {}'.format(recall_score(y_test, y_pred)))\n",
    "print('F1 Score: {}'.format(f1_score(y_test, y_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Using Tensorflow Playground \n",
    "\n",
    "Visit the TensorFlow Playground at https://playground.tensorflow.org/\n",
    "\n",
    "Spend some time playing with this UI to grow your intuition about neural networks. Complete the following problems in a single sitting please.\n",
    "\n",
    "\n",
    "1.\tLayers and patterns: try training the default neural network by clicking the run button (top left). Notice how it quickly finds a good solution for the classification task. Notice that the neurons in the first hidden layer have learned simple patterns, while the neurons in the second hidden layer have learned to combine the simple patterns of the first hidden layer into more complex patterns.  What happens when you add more layers?\n",
    "\n",
    "2.\tActivation function: try replacing the Tanh activation function with the ReLU activation function, and train the network again. Notice that it finds a solution even faster, but this time the boundaries are linear. What about the ReLU function causes this?\n",
    "\n",
    "3.\tLocal minima: modify the network architecture to have just one hidden layer with three neurons. Train it multiple times (to reset the network weights, click the reset button next to the play button). What do you notice about the training time?\n",
    "\n",
    "4.\tToo small: now remove one neuron to keep just 2. Notice that the neural network is now incapable of finding a good solution, even if you try multiple times. What do you observe about the number of parameters and the training set?\n",
    "\n",
    "5.\tLarge enough: next, set the number of neurons to 8 and train the network several times. Notice that it is now consistently fast and never gets stuck. What do you observe about local minima?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6983f06a58192f42c447da62e45706d64312d77c9acaee7903da16ce2e0a4c3a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
